# Защита персональных данных клиентов

Проект, который наглядно демонстрирует, что линейная алгебра может принести *реальную пользу бизнесу*: **защитить персональные данные клиента**. Конфиденциальность - неизбежное требование, диктуемое современностью.

В проекте приводится *строгое матиматическое обоснование* того факта, что умножение признаков на любую обратимую матрицу не влияет на качество моделей линейной регрессии. В этом случае расшифрока данных пользователей возможна только тогда, когда доступен **"ключ"** - искомая обратимая матрица, с помощью которой выполнено преобразование признаков.

Предложен алгоритм для работы с личными данными клиентов, позволяющий не ухудшать качество моделей машинного обучения. 

Выполнена проверка предложенного алгоритма, в ходе которой показано, что качество модели линейной регресии не изменилось в результате использованного подхода к преобразованию личных данных клиентов.


## Библиотеки и инструменты

`pandas`, `numpy`, `matplotlib`, `seaborn`, `sklearn`, `pyplot`, `train_test_split`, `r2_score`
Использована "вручную" подготовленная модель **линейной регрессии**.

## Описание данных

В нашем распоряженнии данные о **5000 клиентах по 5 признакам**

**Признаки:** 
- пол, 
- возраст,
- зарплата застрахованного, 
- количество членов его семьи. 

**Целевой признак:** 
- количество страховых выплат клиенту за последние 5 лет.
